{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Collection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# read in first 10000 rows from csv\r\n",
    "df = pd.read_csv('../data/IRAhandle_tweets_1.csv', nrows=10000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# filter by english language then by not containing '\\?'\r\n",
    "english_df = df[df['language'] == 'English']\r\n",
    "result_df = english_df[~english_df['content'].str.contains('\\?')]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# write to tsv\r\n",
    "result_df.to_csv('../data/clean_data.tsv', sep='\\t', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Annotation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# read in cleaned data\r\n",
    "clean_df = pd.read_csv('../data/clean_data.tsv', sep='\\t')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# add feature 'trump_mention'\r\n",
    "clean_df['trump_mention'] = clean_df['content'].str.contains(\r\n",
    "    '(\\WTrump\\W)|(^Trump\\W)|(\\WTrump$)')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\zcgua\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# write to tsv\r\n",
    "clean_df.to_csv('../dataset.tsv', sep='\\t', index=False,\r\n",
    "                columns=['tweet_id', 'publish_date', 'content', 'trump_mention'])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# read in dataset\r\n",
    "dataset_df = pd.read_csv('../dataset.tsv', sep='\\t')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# calculate the percent trump mention\r\n",
    "frac = len(dataset_df[dataset_df['trump_mention']].index)/len(dataset_df.index)\r\n",
    "frac\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.022490628904623073"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# write to results\r\n",
    "with open('../results.tsv', 'w') as f:\r\n",
    "    f.write(f'result\\tvalue\\nfrac-trump-mentions\\t{frac}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "dup = dataset_df[dataset_df.duplicated(['content'])]\r\n",
    "dup['content']\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "103     Twitter censors conservarives, yet hateful Ant...\n",
       "114     Steve Bannon on Hillary Clinton: \"She's not ve...\n",
       "116     President Trump says he will visit Florida soo...\n",
       "126     This is priceless!! Laura Loomer sneaks into H...\n",
       "163     CNN won't show it's viewers these amazing patr...\n",
       "186     CNN broadcast cut off an African-American Trum...\n",
       "213     The fact that Obama was wiretapping Trump Towe...\n",
       "227     If Melania Trump was a liberal Democrat, she'd...\n",
       "230        '@realDonaldTrump We love you, Mr. President!'\n",
       "239     Floyd Mayweather defends Trump: \"You never hea...\n",
       "256     A Maine woman says that she would rather go to...\n",
       "285         '@realDonaldTrump We love you Mr. President!'\n",
       "290     Daughter of fallen Navy Sailor delivers powerf...\n",
       "297     Chicago teacher places flag on the ground for ...\n",
       "310     Because of #FakeNews my people are not getting...\n",
       "326     You won't see this on CNN https://t.co/N8ZqZso4sC\n",
       "334     There's a White House petition to protect our ...\n",
       "335     United we stand, divided we fall. Sign the pet...\n",
       "338     #IfIWerePresidentForOneDay I would condemn cen...\n",
       "340     The new face of censorship. We need to fight b...\n",
       "4200             '@howiemandel @nbcagt #BlackLivesMatter'\n",
       "4465                     '@selenagomez #BlackLivesMatter'\n",
       "4469                     '@selenagomez #BlackLivesMatter'\n",
       "Name: content, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "len(dup.index)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f5e1b8adddfa7131b5b33ad95fec655eed8e7c66dcdcbd512800a7776a44e6ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}